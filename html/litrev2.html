<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title></title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (https://tug.org/tex4ht/)"> 
<meta name="originator" content="TeX4ht (https://tug.org/tex4ht/)"> 
<!-- html --> 
<meta name="src" content="litrev.tex"> 
<link rel="stylesheet" type="text/css" href="litrev.css"> 
</head><body 
>
 <div class="footnote-text">
 <!--l. 404--><p class="noindent" ><span class="footnote-mark"><a 
 id="fn2x0">    <sup class="textsuperscript">&#8224;</sup></a></span><tspan font-family="cmr" font-size="10">Note here that we say all learning methods use policy iteration - in reality some</tspan>
 <tspan font-family="cmr" font-size="10">methods use value iteration; where we iterate over all states updating value estimates for</tspan>
 <tspan font-family="cmr" font-size="10">each state until our V-function converges, and then find the optimal policy in one</tspan>
 <tspan font-family="cmr" font-size="10">pass.</tspan></div>
     
</body></html> 
